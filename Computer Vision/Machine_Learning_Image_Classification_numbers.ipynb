{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning Image Classification numbers.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPnvFxiNFJTj"
      },
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import pandas as pd\n",
        "import os\n",
        "import argparse\n",
        "from skimage import feature\n",
        "from imutils import paths\n",
        "from imutils import build_montages\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import svm \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLObvA8hWhec"
      },
      "source": [
        "LOAD DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW3KgnyfODOk"
      },
      "source": [
        "dataset_dir = '/content/drive/My Drive/numbers'\n",
        "\n",
        "training_path = os.path.join(dataset_dir, 'training')\n",
        "testing_path = os.path.join(dataset_dir, 'testing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "314lW4UcJqQ1"
      },
      "source": [
        "def preprocess(image, image_size=128):\n",
        "  image = cv.cvtColor(image, cv.COLOR_BGR2GRAY) #Ubah menjadi greyscale\n",
        "  image = cv.resize(image, (image_size, image_size)) #resize gambar menjadi suatu ukuran (default = 128)\n",
        "\n",
        "  image = cv.threshold(image, 0, 255, cv.THRESH_BINARY_INV | cv.THRESH_OTSU)[1] #melakukan thresholding dan mengambil gambar hasil thresholding\n",
        "\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIEqKup8MtNU"
      },
      "source": [
        "# From: https://www.pyimagesearch.com/2019/04/29/detecting-parkinsons-disease-with-opencv-computer-vision-and-the-spiral-wave-test/\n",
        "def quantify_image_hog(image): #HOG Features\n",
        "  features = feature.hog(image, orientations=9, pixels_per_cell=(10, 10), cells_per_block=(2, 2), transform_sqrt=True, block_norm='L1')\n",
        "\n",
        "  return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svKSWRHXMwJy"
      },
      "source": [
        "# From: https://www.pyimagesearch.com/2015/12/07/local-binary-patterns-with-python-opencv/\n",
        "def quantify_image_lbp(image):\n",
        "  features = feature.local_binary_pattern(image, 24, 8, method='uniform')\n",
        "  \n",
        "  (hist, _) = np.histogram(features.flatten(), bins=np.arange(0, 26), range=(0, 26))\n",
        "\n",
        "  hist = hist.astype('float')\n",
        "  hist /= (hist.sum() + 1e-7)\n",
        "\n",
        "  return hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3ALgm5Pssdj"
      },
      "source": [
        "def load_split(path, image_size=200, extraction_method='hog'):\n",
        "  image_paths = list(paths.list_images(path))\n",
        "  data = []\n",
        "  labels = []\n",
        "\n",
        "  for image_path in image_paths:\n",
        "    label = image_path.split(os.path.sep)[-2]\n",
        "\n",
        "    image = cv.imread(image_path)\n",
        "    image = preprocess(image, image_size=image_size)\n",
        "\n",
        "    if extraction_method == 'hog':\n",
        "      features = quantify_image_hog(image)\n",
        "    elif extraction_method == 'lbp':\n",
        "      features = quantify_image_lbp(image)\n",
        "\n",
        "    data.append(features)\n",
        "    labels.append(label)\n",
        "\n",
        "  return (np.array(data), np.array(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y5Wd1OesOVd"
      },
      "source": [
        "#HOG 128\n",
        "resize_image_size_200 = 200\n",
        "extraction_method = 'hog'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GP_VH9YsV3z",
        "outputId": "dac47992-41d6-4570-ab3e-3fe95a7f440e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(X_train, y_train) = load_split(training_path, image_size=resize_image_size_200, extraction_method=extraction_method)\n",
        "(X_test, y_test) = load_split(testing_path, image_size=resize_image_size_200, extraction_method=extraction_method)\n",
        "\n",
        "print('Data berhasil diupload!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data berhasil diupload!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FyHIoSXZA1A"
      },
      "source": [
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BqPnpZyZGKs",
        "outputId": "d4061649-7888-4547-d364-665dcbaacabb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKlbuHCJZG1J",
        "outputId": "e032b85d-6c90-4675-ee65-7e87d9f79996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS5jFoKZ6Mv6",
        "outputId": "253e414c-b092-4d8c-ebe7-321e97a565aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "lin_svc = LinearSVC()\n",
        "lin_svc.get_params()\n",
        "\n",
        "lin_svc = LinearSVC(penalty='l2', loss='hinge', random_state=10)\n",
        "lin_svc.fit(X_train, y_train)\n",
        "prediksi_lin_svc_test = lin_svc.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, prediksi_lin_svc_test)\n",
        "cr = classification_report(y_test, prediksi_lin_svc_test)\n",
        "\n",
        "print('Accuracy of SVM on test set: {:.2f}'.format(lin_svc.score(X_test, y_test)))\n",
        "print('F1 {:.2f}'.format(f1_score(y_test, prediksi_lin_svc_test, average='macro')))\n",
        "print('Precision{:.2f}'.format(precision_score(y_test, prediksi_lin_svc_test, average='macro')))\n",
        "print('Recall {:.2f}'.format(recall_score(y_test, prediksi_lin_svc_test, average='macro')))\n",
        "print()\n",
        "print(cr)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of SVM on test set: 1.00\n",
            "F1 1.00\n",
            "Precision1.00\n",
            "Recall 1.00\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       300\n",
            "           1       1.00      1.00      1.00       300\n",
            "           2       1.00      0.99      0.99       300\n",
            "\n",
            "    accuracy                           1.00       900\n",
            "   macro avg       1.00      1.00      1.00       900\n",
            "weighted avg       1.00      1.00      1.00       900\n",
            "\n",
            "[[299   0   1]\n",
            " [  1 299   0]\n",
            " [  2   0 298]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX5KBJ53ZWBu",
        "outputId": "3abf7355-5531-4302-fd91-69520663111a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "predictions = logreg.predict(X_test)\n",
        "\n",
        "classification_report(y_test, predictions)\n",
        "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test))) # .score() -> Accuracy\n",
        "print(\"F1\", f1_score(y_test, predictions, average=\"macro\"))\n",
        "print(\"Precision\", precision_score(y_test, predictions, average=\"macro\"))\n",
        "print(\"Recall\", recall_score(y_test, predictions, average=\"macro\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of logistic regression classifier on test set: 0.99\n",
            "F1 0.9933405222345085\n",
            "Precision 0.9933952094039813\n",
            "Recall 0.9933333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkWaPcIasruh",
        "outputId": "e92a0b14-26a8-4eb7-d5eb-72c2c49c7182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=10)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "classification_report(y_test, predictions)\n",
        "\n",
        "print(pd.crosstab(y_test, predictions, rownames=['True'], colnames=['Predicted'], margins=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted    0    1    2  All\n",
            "True                         \n",
            "0          297    0    3  300\n",
            "1            0  297    3  300\n",
            "2            4    1  295  300\n",
            "All        301  298  301  900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8mbHPX51Ktx",
        "outputId": "0515c593-92b2-4bd0-d888-44d266e76e22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "print(classification_report(y_test, predictions))\n",
        "\n",
        "print('Accuracy of Random Forest on test set: {:.2f}'.format(model.score(X_test, y_test)))\n",
        "print(\"F1\", f1_score(y_test, predictions, average=\"macro\"))\n",
        "print(\"Precision\", precision_score(y_test, predictions, average=\"macro\"))\n",
        "print(\"Recall\", recall_score(y_test, predictions, average=\"macro\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       300\n",
            "           1       1.00      0.99      0.99       300\n",
            "           2       0.98      0.98      0.98       300\n",
            "\n",
            "    accuracy                           0.99       900\n",
            "   macro avg       0.99      0.99      0.99       900\n",
            "weighted avg       0.99      0.99      0.99       900\n",
            "\n",
            "Accuracy of Random Forest on test set: 0.99\n",
            "F1 0.9877869845315406\n",
            "Precision 0.987807234646629\n",
            "Recall 0.9877777777777778\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}